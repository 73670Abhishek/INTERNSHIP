{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7d8bfe",
   "metadata": {},
   "source": [
    "# Please visit https://www.cnbc.com/world/?region=world and scrap-\n",
    " #a) headings\n",
    " #b) date\n",
    " #c) News link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c3acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "articles = soup.find_all('div', class_='Card-titleContainer')  \n",
    "\n",
    "for article in articles:\n",
    "    heading_element = article.find('a', class_='Card-title')\n",
    "    if heading_element:\n",
    "        heading = heading_element.text.strip()\n",
    "    else:\n",
    "        heading = \"No heading found\"\n",
    "\n",
    "    date_element = article.find('time', class_='Card-time')  \n",
    "    if date_element:\n",
    "        date = date_element.text.strip()\n",
    "    else:\n",
    "        date = \"No date found\"\n",
    "\n",
    "    link_element = article.find('a', href=True)\n",
    "    if link_element:\n",
    "        news_link = link_element['href']\n",
    "    else:\n",
    "        news_link = \"No link found\"\n",
    "\n",
    "    print(f\"Heading: {heading}\")\n",
    "    print(f\"Date: {date}\")\n",
    "    print(f\"News Link: {news_link}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be17b9b8",
   "metadata": {},
   "source": [
    "# Please visit https://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/most-downloadedarticles/ and scrap\n",
    " #a) Paper title\n",
    " #b) date\n",
    " #c) Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e10329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper Title: Implementation of artificial intelligence in agriculture for optimisation of irrigation and application of pesticides and herbicides\n",
      "Date: 2020\n",
      "Author: Tanha Talaviya |  Dhara Shah |  Nivedita Patel |  Hiteshri Yagnik |  Manan Shah\n",
      "\n",
      "Paper Title: Review of agricultural IoT technology\n",
      "Date: 2022\n",
      "Author: Jinyuan Xu |  Baoxing Gu |  Guangzhao Tian\n",
      "\n",
      "Paper Title: A comprehensive review on automation in agriculture using artificial intelligence\n",
      "Date: June 2019\n",
      "Author: Kirtan Jha |  Aalap Doshi |  Poojan Patel |  Manan Shah\n",
      "\n",
      "Paper Title: Automation and digitization of agriculture using artificial intelligence and internet of things\n",
      "Date: 2021\n",
      "Author: A. Subeesh |  C.R. Mehta\n",
      "\n",
      "Paper Title: Real-time hyperspectral imaging for the in-field estimation of strawberry ripeness with deep learning\n",
      "Date: 2020\n",
      "Author: Zongmei Gao |  Yuanyuan Shao |  Guantao Xuan |  Yongxian Wang |  Yi Liu |  Xiang Han\n",
      "\n",
      "Paper Title: A review of imaging techniques for plant disease detection\n",
      "Date: 2020\n",
      "Author: Vijai Singh |  Namita Sharma |  Shikha Singh\n",
      "\n",
      "Paper Title: Deep learning based computer vision approaches for smart agricultural applications\n",
      "Date: 2022\n",
      "Author: V.G. Dhanya |  A. Subeesh |  N.L. Kushwaha |  Dinesh Kumar Vishwakarma |  T. Nagesh Kumar |  G. Ritika |  A.N. Singh\n",
      "\n",
      "Paper Title: Applications of electronic nose (e-nose) and electronic tongue (e-tongue) in food quality-related properties determination: A review\n",
      "Date: 2020\n",
      "Author: Juzhong Tan |  Jie Xu\n",
      "\n",
      "Paper Title: Fruit ripeness classification: A survey\n",
      "Date: March 2023\n",
      "Author: Matteo Rizzo |  Matteo Marcuzzo |  Alessandro Zangari |  Andrea Gasparetto |  Andrea Albarelli\n",
      "\n",
      "Paper Title: How artificial intelligence uses to achieve the agriculture sustainability: Systematic review\n",
      "Date: June 2023\n",
      "Author: Vilani Sachithra |  L.D.C.S. Subhashini\n",
      "\n",
      "Paper Title: Transfer Learning for Multi-Crop Leaf Disease Image Classification using Convolutional Neural Network VGG\n",
      "Date: 2022\n",
      "Author: Ananda S. Paymode |  Vandana B. Malode\n",
      "\n",
      "Paper Title: DeepRice: A deep learning and deep feature based classification of Rice leaf disease subtypes\n",
      "Date: March 2024\n",
      "Author: P. Isaac Ritharson |  Kumudha Raimond |  X. Anitha Mary |  Jennifer Eunice Robert |  Andrew J\n",
      "\n",
      "Paper Title: Comparison of CNN-based deep learning architectures for rice diseases classification\n",
      "Date: September 2023\n",
      "Author: Md Taimur Ahad |  Yan Li |  Bo Song |  Touhid Bhuiyan\n",
      "\n",
      "Paper Title: Plant disease detection using hybrid model based on convolutional autoencoder and convolutional neural network\n",
      "Date: 2021\n",
      "Author: Punam Bedi |  Pushkar Gole\n",
      "\n",
      "Paper Title: Using an improved lightweight YOLOv8 model for real-time detection of multi-stage apple fruit in complex orchard environments\n",
      "Date: March 2024\n",
      "Author: Baoling Ma |  Zhixin Hua |  Yuchen Wen |  Hongxing Deng |  Yongjie Zhao |  Liuru Pu |  Huaibo Song\n",
      "\n",
      "Paper Title: Deep convolutional neural network models for weed detection in polyhouse grown bell peppers\n",
      "Date: 2022\n",
      "Author: A. Subeesh |  S. Bhole |  K. Singh |  N.S. Chandel |  Y.A. Rajwade |  K.V.R. Rao |  S.P. Kumar |  D. Jat\n",
      "\n",
      "Paper Title: A systematic review of machine learning techniques for cattle identification: Datasets, methods and future directions\n",
      "Date: 2022\n",
      "Author: Md Ekramul Hossain |  Muhammad Ashad Kabir |  Lihong Zheng |  Dave L. Swain |  Shawn McGrath |  Jonathan Medway\n",
      "\n",
      "Paper Title: Examining the interplay between artificial intelligence and the agri-food industry\n",
      "Date: 2022\n",
      "Author: Abderahman Rejeb |  Karim Rejeb |  Suhaiza Zailani |  John G. Keogh |  Andrea Appolloni\n",
      "\n",
      "Paper Title: Machine learning in nutrient management: A review\n",
      "Date: September 2023\n",
      "Author: Oumnia Ennaji |  Leonardus Vergütz |  Achraf El Allali\n",
      "\n",
      "Paper Title: Artificial cognition for applications in smart agriculture: A comprehensive review\n",
      "Date: 2020\n",
      "Author: Misbah Pathan |  Nivedita Patel |  Hiteshri Yagnik |  Manan Shah\n",
      "\n",
      "Paper Title: A review on computer vision systems in monitoring of poultry: A welfare perspective\n",
      "Date: 2020\n",
      "Author: Cedric Okinda |  Innocent Nyalala |  Tchalla Korohou |  Celestine Okinda |  Jintao Wang |  Tracy Achieng |  Patrick Wamalwa |  Tai Mang |  Mingxia Shen\n",
      "\n",
      "Paper Title: Machine learning for weed–plant discrimination in agriculture 5.0: An in-depth review\n",
      "Date: December 2023\n",
      "Author: Filbert H. Juwono |  W.K. Wong |  Seema Verma |  Neha Shekhawat |  Basil Andy Lease |  Catur Apriono\n",
      "\n",
      "Paper Title: Automated quality inspection of baby corn using image processing and deep learning\n",
      "Date: March 2024\n",
      "Author: Kris Wonggasem |  Pongsan Chakranon |  Papis Wongchaisuwat\n",
      "\n",
      "Paper Title: Explainable artificial intelligence and interpretable machine learning for agricultural data analysis\n",
      "Date: 2022\n",
      "Author: Masahiro Ryo\n",
      "\n",
      "Paper Title: LeafSpotNet: A deep learning framework for detecting leaf spot disease in jasmine plants\n",
      "Date: June 2024\n",
      "Author: Shwetha V |  Arnav Bhagwat |  Vijaya Laxmi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/most-downloaded-articles/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "articles = soup.find_all('div', class_='article-listing')\n",
    "\n",
    "for article in articles:\n",
    "    # Paper Title\n",
    "    title_element = article.find('h2', class_='h5 article-title')\n",
    "    title = title_element.text.strip() if title_element else \"No title found\"\n",
    "    \n",
    "    # Date\n",
    "    date_element = article.find('p', class_= 'article-date')\n",
    "    date = date_element.text.strip() if date_element else \"No date found\"\n",
    "    \n",
    "    # Author\n",
    "    author_element = article.find('p', class_='article-authors')\n",
    "    author = author_element.text.strip() if author_element else \"No author found\"\n",
    "\n",
    "    print(f\"Paper Title: {title}\")\n",
    "    print(f\"Date: {date}\")\n",
    "    print(f\"Author: {author}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4e216",
   "metadata": {},
   "source": [
    "#  Write a python program to scrape first 10 product details which include product name , price , Image URL from\n",
    "https://www.bewakoof.com/bestseller?sort=popular ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74f44deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name: No name found\n",
      "Price: No price found\n",
      "Image URL: No image URL found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.bewakoof.com/bestseller?sort=popular%20\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "products = soup.find_all('div', class_='categoryWrapper')[:10]\n",
    "\n",
    "for product in products:\n",
    "    # Product Name\n",
    "    name_element = product.find('h1', class_='ProductName')\n",
    "    name = name_element.text.strip() if name_element else \"No name found\"\n",
    "    \n",
    "    # Product Price\n",
    "    price_element = product.find('div', class_='discountedPriceText clr-p-black   false')\n",
    "    price = price_element.text.strip() if price_element else \"No price found\"\n",
    "    \n",
    "    # Image URL\n",
    "    image_element = product.find('div',class_='productImg')\n",
    "    if image_element and 'data-src' in image_element.attrs:\n",
    "        image_url = image_element['data-src']\n",
    "    else:\n",
    "        image_url = \"No image URL found\"\n",
    "\n",
    "    print(f\"Product Name: {name}\")\n",
    "    print(f\"Price: {price}\")\n",
    "    print(f\"Image URL: {image_url}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999389cb",
   "metadata": {},
   "source": [
    "# Write a python program to scrape details of all the posts from https://www.patreon.com/coreyms .Scrape the heading, date, content and the likes for the video from the link for the youtube video from the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56e20bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.patreon.com/coreyms\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all post containers\n",
    "posts = soup.find_all('div', class_='post')\n",
    "\n",
    "# Iterate through each post\n",
    "for post in posts:\n",
    "     # Extract heading\n",
    "    heading_element = post.find('h3', class_='post__title')\n",
    "    heading = heading_element.text.strip() if heading_element else \"No heading found\"\n",
    "    \n",
    "     # Extract date\n",
    "    date_element = post.find('time', class_='datetime')\n",
    "    date = date_element.text.strip() if date_element else \"No date found\"\n",
    "    \n",
    "     # Extract content\n",
    "    content_element = post.find('div', class_='Post_Content')\n",
    "    content = content_element.text.strip() if content_element else \"No content found\"\n",
    "    \n",
    "     # Extract YouTube video link and likes\n",
    "    youtube_link_element = post.find('a', class_='post__youtube-link')\n",
    "    youtube_link = youtube_link_element['href'] if youtube_link_element else \"No YouTube link found\"\n",
    "\n",
    "    likes_element = post.find('span', class_='post__likes')\n",
    "    likes = likes_element.text.strip() if likes_element else \"No likes found\"\n",
    "    \n",
    "    # Print the details\n",
    "    print(\"Heading:\", heading)\n",
    "    print(\"Date:\", date)\n",
    "    print(\"Content:\", content)\n",
    "    print(\"YouTube Link:\", youtube_link)\n",
    "    print(\"Likes:\", likes)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d0b49",
   "metadata": {},
   "source": [
    "# Write a python program to scrape house details from mentioned URL. It should include house title, location,area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar,Rajaji Nagar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d7da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the localities\n",
    "localities = [\"Indira Nagar\", \"Jayanagar\", \"Rajaji Nagar\"]\n",
    "\n",
    "# Iterate over each locality\n",
    "for locality in localities:\n",
    "    url = f\"https://www.nobroker.in/property/sale/bangalore/{locality.lower().replace(' ', '-')}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    print(f\"Scraping houses in {locality}...\\n\")\n",
    "    \n",
    "    # Find all house containers\n",
    "    houses = soup.find_all('div', class_='card')\n",
    "    \n",
    "    for house in houses:\n",
    "        # Extract house title\n",
    "        title_element = house.find('h2', class_='heading-6')\n",
    "        title = title_element.text.strip() if title_element else \"No title found\"\n",
    "\n",
    "        # Extract location\n",
    "        location_element = house.find('h1', class_='text-16')\n",
    "        location = location_element.text.strip() if location_element else \"No location found\"\n",
    "\n",
    "        # Extract area\n",
    "        area_element = house.find('p', class_='text-left pl-1.5p ab:p-0 tab:text-12 tab:mt-0.5p tab:mb-0 tab:pl-0') \n",
    "        area = area_element.text.strip() if area_element else \"No area found\"\n",
    "\n",
    "        # Extract EMI\n",
    "        emi_element = house.find('div', class_='font-semi-bold')\n",
    "        emi = emi_element.text.strip() if emi_element else \"No EMI found\"\n",
    "\n",
    "        # Extract price\n",
    "        price_element = house.find('span', class_='text-18 font-bold')\n",
    "        price = price_element.text.strip() if price_element else \"No price found\"\n",
    "\n",
    "        # Print the details\n",
    "        print(\"Title:\", title)\n",
    "        print(\"Location:\", location)\n",
    "        print(\"Area:\", area)\n",
    "        print(\"EMI:\", emi)\n",
    "        print(\"Price:\", price)\n",
    "        print()\n",
    "    \n",
    "    print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
